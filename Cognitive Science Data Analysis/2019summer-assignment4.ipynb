{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/xiaoyingliu/Desktop\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot\n",
    "import random as rd \n",
    "from sklearn.model_selection import train_test_split\n",
    "%cd '/Users/xiaoyingliu/desktop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. [20pts] Write an implementation of the perceptron learning algorithm that first loads images for the\n",
    "#digit “0” and then for the digit “1”. Start with random weights from a normal distribution. Compute the\n",
    "#average accuracy on blocks of 25 items and plot this accuracy until you think it won’t get better.\n",
    "DIM = (28,28) \n",
    "def load_image_files(n, path=\"images/\"):   \n",
    "    # helper file to help load the images    \n",
    "    # returns a list of numpy vectors    \n",
    "    images = []    \n",
    "    for f in os.listdir(os.path.join(path,str(n))): \n",
    "        # read files in the path       \n",
    "        p = os.path.join(path,str(n),f)        \n",
    "        if os.path.isfile(p):            \n",
    "            i = n.loadtxt(p)            \n",
    "            assert i.shape == DIM # just check the dimensions here            \n",
    "            # i is loaded as a matrix, but we are going to flatten it into a singlevector            \n",
    "            images.append(i.flatten())    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'loadtxt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-50715f08ddcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-223-5840d039f0d3>\u001b[0m in \u001b[0;36mload_image_files\u001b[0;34m(n, path)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDIM\u001b[0m \u001b[0;31m# just check the dimensions here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# i is loaded as a matrix, but we are going to flatten it into a singlevector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'loadtxt'"
     ]
    }
   ],
   "source": [
    "A = load_image_files(0)\n",
    "B = load_image_files(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add labels as second column to A and B\n",
    "label0=np.zeros((5923,1))\n",
    "label1=np.ones((6742,1))\n",
    "A_withlabel=np.column_stack((A, label0))\n",
    "B_withlabel=np.column_stack((B,label1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(A[0]) # the total sizeassert should be 784\n",
    "\n",
    "N == DIM[0]*DIM[1] # just check our sizes to be sure\n",
    "# set up some random initial weights\n",
    "weights = np.random.normal(0,1,size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show initial weights #784 entries\n",
    "np.shape(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification function\n",
    "def predict(data_point, weights):\n",
    "\tb = np.dot(data_point, weights)\n",
    "\ta = b>0\n",
    "\treturn a*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(weights, data_point, labels, alpha=.1):\n",
    "\tpredicted = predict(data_point, weights)\n",
    "\tweight_temp = np.zeros(np.shape(weights))\n",
    "\tweight_temp = alpha*(labels-predicted)*data_point\n",
    "\treturn weight_temp+weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in total 12665 images\n",
    "AB=np.vstack((A_withlabel,B_withlabel))\n",
    "np.shape(AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to randomly shuffle AB,this is a substitution of sampling from AB\n",
    "#if label match, corretc+1 total+1 if not total+1 when total =25, acc=correct/total and print( accurat) it will show convergence\n",
    "def train_perceptron(data, weights, alpha = .001, iterations = 10):\n",
    "    for j in range(0, iterations):\n",
    "        for i in range(0, 12665):\n",
    "            weights = update(weights, data[i][:-1], data[i][783:784], alpha)\n",
    "    return weights\n",
    "\n",
    "final_weights=train_perceptron(AB,weights,alpha=0.001,iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test accuracy\n",
    "def test_all(data, labels, weights):\n",
    "\ta, b = np.shape(labels)\n",
    "\tpredicted = predict(data, weights)\n",
    "\tcorrect = predicted == labels[:,0]\n",
    "    \n",
    "\taccuracy = np.sum(correct)/float(a)\n",
    "\treturn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975523095144098"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all(AB[:, :-1],AB[:, 783:784] ,final_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion:as the training number of images and iterations increases, accuracy has been increased and gradually converging to 100%. After \n",
    "#10 interations, accuracy has been increased to 99.76%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. [5pts] Does your solution in Q1 converge on 100% accuracy or not? What does this mean in terms of\n",
    "#the linear separability of “0” and “1” on this feature space?\n",
    "#Ans: yes, it means that 0 and 1 in the feature space is linearly seperable, that our algorithm could be used as a linear seperator for 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. [15pts] Reshape (numpy.reshape) your weight vector after training so that it is a 28x28 matrix. This\n",
    "#corresponds to the weight assigned to each pixel in the image. Show a picture of this weight matrix and\n",
    "#interpret it in a sentence or two. What do large negative and large positive values mean, intuitively?\n",
    "#What do numbers near zero mean? Why does this matrix look the way that it does, in terms of where\n",
    "#large positive and negative terms are located?\n",
    "#Ans:\n",
    "#use heat matrix to display weights. Large values are useful, more predictable. small valuea are not as predictable as large numbers in weight matrix. \n",
    "#Thus, the location of large numbers and small numbers are an intuitive way of showing whethere that location is an important factor as in predicting\n",
    "#the specific hand written digit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-19b1f85f8ff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGreys_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m122\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "#4. [10pts] What should you expect to happen if you set the elements of the weight vector which are\n",
    "#close to zero to be actually zero? Do this for the 10, 20, 30, … 780 weight values closest to zero (in\n",
    "#absolute value) and plot the resulting accuracies on 1000 random classifications of “0” vs “1”. What\n",
    "#does this tell you about the proportion of the image which is diagnostic about “0” vs “1”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans: If we set near zeros to zeros. We would eliminate these location-wise numbers as a predction factor in the\n",
    "#linear seperator. My expectation is that the accuracy might be decreased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. [20pts] Next show a matrix of the classification accuracy of each pair of digits after enough training.\n",
    "#Make this a plot (with colors for accuracy rather than numbers). Does it match your intuitions about\n",
    "#which pairs should be easy vs. hard? Why or why not?\n",
    "#Ans: we could construct an algoritm which can identify all numbers at the same time. We need the following 2 functions. one is for \n",
    "#classifying all numbers, the other is for whenever the classfier gives 2 conflicting results, we could use the the highest value as the result, to get the one and only, \n",
    "#most reliable prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return a set of weights which could classfiy all digits\n",
    "def all_numbers(data,labels):\n",
    "\tc,d = np.shape(data)\n",
    "\tw = create_weights(data)\n",
    "\tweights = []\n",
    "\tfor i in range(0, 10):\n",
    "\t\tz = same_number(labels, i)\n",
    "\t\ta = train_perceptron(data, z, w, .001, 4)\n",
    "\t\tweights.append(a[:,0])\n",
    "\treturn np.asarray(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 2, 7, ..., 0, 3, 6])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_all(data, weights):\n",
    "\ta = np.dot(data,np.transpose(weights))\n",
    "\tb = len(np.shape(data))\n",
    "\tif b == 1:\n",
    "\t\treturn np.argmax(a)\n",
    "\treturn np.argmax(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more iterations and moderate learning rate will give out best results, we will do 200 iterations and alpha as 0.0001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
